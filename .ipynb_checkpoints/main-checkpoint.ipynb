{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv, DataFrame\n",
    "from random import random\n",
    "import time as time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script assumes that time gap between 2 stations would always remain same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the routes from end station to end station\n",
    "end_to_end_routes = [\n",
    "  ['CSMT', 'MASJID', 'SANDHURST ROAD', 'BYCULLA', 'CHINCHPOKLI', 'CURREY ROAD',\n",
    "  'PAREL', 'DADAR', 'MATUNGA', 'SION', 'KURLA', 'VIDYAVIHAR', 'GHATKOPAR',\n",
    "  'VIKHROLI', 'KANJUR MARG', 'BHANDUP', 'NAHUR', 'MULUND', 'THANE', 'KALVA',\n",
    "  'MUMBRA', 'DIVA JN', 'KOPAR', 'DOMBIVLI', 'THAKURLI', 'KALYAN', 'SHAHAD',\n",
    "  'AMBIVLI', 'TITWALA', 'KHADAVLI', 'VASIND', 'ASANGAON', 'ATGAON', 'THANSIT',\n",
    "  'KHARDI', 'UMBERMALI', 'KASARA'],\n",
    "  ['CSMT', 'MASJID', 'SANDHURST ROAD', 'BYCULLA', 'CHINCHPOKLI', 'CURREY ROAD',\n",
    "  'PAREL', 'DADAR', 'MATUNGA', 'SION', 'KURLA', 'VIDYAVIHAR', 'GHATKOPAR',\n",
    "  'VIKHROLI', 'KANJUR MARG', 'BHANDUP', 'NAHUR', 'MULUND', 'THANE', 'KALVA',\n",
    "  'MUMBRA', 'DIVA JN', 'KOPAR', 'DOMBIVLI', 'THAKURLI', 'KALYAN', 'VITHALWADI',\n",
    "  'ULHAS NAGAR', 'AMBERNATH', 'BADLAPUR', 'VANGANI', 'SHELU', 'NERAL',\n",
    "  'BHIVPURI ROAD', 'KARJAT', 'PALASDHARI', 'KELAVLI', 'DOLAVLI', 'LOWJEE',\n",
    "  'KHOPOLI']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time between stations\n",
    "time_between_stations = [\n",
    "  [3, 2, 3, 2, 2, 3, 3, 3, 3, 4, 3, 3, 4, 3, 3, 3, 3, 5, 4, 6, 4, 5, 3, 4, 7, 4,\n",
    "  3, 6, 7, 7, 9, 9, 4, 6, 5, 13],\n",
    "  [3, 2, 3, 2, 2, 3, 3, 3, 3, 4, 3, 3, 4, 3, 3, 3, 3, 5, 4, 6, 4, 5, 3, 4, 7, 4,\n",
    "  3, 4, 7, 9, 4, 4, 7, 9, 5, 7, 3, 4, 6]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty dictionary of routes from all station to all station\n",
    "routes = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty dictionary of time delays between adjacent stations\n",
    "time_delay = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For all end to end routes\n",
    "for a, e2e_route in enumerate(end_to_end_routes):\n",
    "\n",
    "  # For all start stations\n",
    "  for i, start in enumerate(e2e_route):\n",
    "\n",
    "    # For all end stations\n",
    "    for j, end in enumerate(e2e_route):\n",
    "\n",
    "      # If they are not equal\n",
    "      if start != end:\n",
    "\n",
    "        # Store the list index and sub list indices of both direction\n",
    "        routes[start, end] = a, i, j\n",
    "        routes[end, start] = a, j, i\n",
    "\n",
    "        # Store the time delay if the stations are adjacent\n",
    "        if abs(i - j) == 1:\n",
    "          time_delay[frozenset([start,end])] = time_between_stations[a][min(i,j)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the train_data file\n",
    "with open('train_data.csv', 'w') as out:\n",
    "\n",
    "  # Write header in output\n",
    "  out.write('start,end,start_time,speed,station,time\\n')\n",
    "\n",
    "  # Open the input file\n",
    "  with open('input_for_generate_train_data.txt') as inp:\n",
    "\n",
    "    # For all lines in the file\n",
    "    for line in inp.readlines():\n",
    "\n",
    "      # Extract start, end and time from line\n",
    "      start, end, time = line.strip().split(',')\n",
    "      start, end = start.upper(), end.upper()\n",
    "\n",
    "      # Extract route info\n",
    "      a, i, j = routes[start, end]\n",
    "\n",
    "      # Direction for up or down\n",
    "      direction = (j-i)//abs(j-i)\n",
    "\n",
    "      # Find min and max of i and j\n",
    "      mx, mn = max(i, j), min(i, j)\n",
    "\n",
    "      # Find route from the route info\n",
    "      route = end_to_end_routes[a][mn: mx+1][::direction]\n",
    "\n",
    "      # Format the time\n",
    "      start_time = f'{time[:2]}:{time[2:]}'\n",
    "\n",
    "      # Train identifier\n",
    "      train_id = f'{start},{end},{start_time},S'\n",
    "\n",
    "      # Write info for first station\n",
    "      out.write(f'{train_id},{start},{start_time}\\n')\n",
    "\n",
    "      # Extract hour and minute from time\n",
    "      hour, minute = int(time[:2]), int(time[2:])\n",
    "\n",
    "      # Store the previous station\n",
    "      prev_station = start\n",
    "\n",
    "      # For all stations except for first\n",
    "      for station in route[1:]:\n",
    "\n",
    "        # Add minute delay\n",
    "        minute += time_delay[frozenset([station, prev_station])]\n",
    "\n",
    "        # Current station becomes previous_station for next station\n",
    "        prev_station = station\n",
    "\n",
    "        # If minute is an hour or more\n",
    "        if minute > 59:\n",
    "\n",
    "          # Calculate hour and minute\n",
    "          minute %= 60\n",
    "          hour = (hour + 1) % 24\n",
    "        \n",
    "        # Write output\n",
    "        out.write(f'{train_id},{station},{hour:02}:{minute:02}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum delay that a train can be late for\n",
    "MAX_DELAY = 3\n",
    "\n",
    "# Divide the whole sample space into total parts\n",
    "parts = list(range(MAX_DELAY + 1, 0, -1))\n",
    "\n",
    "# This list is the result of the above probability distribution\n",
    "delay_list = list(range(MAX_DELAY+1))\n",
    "\n",
    "# Sum all the parts\n",
    "total = sum(parts)\n",
    "\n",
    "# Initialize an empty probability threshold list\n",
    "prob_threshold = [0]\n",
    "\n",
    "# For all parts\n",
    "for p in parts:\n",
    "\n",
    "  # Append the cummulative threshold to the list\n",
    "  prob_threshold.append(prob_threshold[-1] + p/total)\n",
    "\n",
    "# Delete the dummy first value\n",
    "del prob_threshold[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function adds random delay to the time passed\n",
    "# Probability distribution [0, MAX_DELAY] in a half bell curve\n",
    "def random_delay(y, mo, d, h, mi):\n",
    "\n",
    "  # Pick a random number in [0, 1)\n",
    "  r = random()\n",
    "\n",
    "  # For all prob threshold\n",
    "  for i, prob in enumerate(prob_threshold):\n",
    "\n",
    "    # If it crosses the threshold\n",
    "    if r < prob:\n",
    "\n",
    "      # This will be the delay\n",
    "      delay = delay_list[i]\n",
    "      break\n",
    "  \n",
    "  # Return the time after adding delay\n",
    "  return time.mktime(\n",
    "          time.strptime(f'{y} {mo} {d} {h} {mi}', '%Y %m %d %H %M')\n",
    "         ) + delay * 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read train_data csv as time table tt\n",
    "tt = read_csv('train_data.csv')\n",
    "\n",
    "# Initialize a none dataframe for final output data\n",
    "final_data = DataFrame()\n",
    "\n",
    "# Year is 2020\n",
    "y = 2020\n",
    "\n",
    "# Iterate month from Jan to Apr\n",
    "for mo in range(1, 5):\n",
    "\n",
    "  # Iterate for all days in the month\n",
    "  for d in range(1, {1: 31, 2: 29, 3: 31, 4: 30}[mo] + 1):\n",
    "\n",
    "    print(f'{y} {mo} {d}')\n",
    "\n",
    "    # Make a copy of time table\n",
    "    df = tt.copy()\n",
    "\n",
    "    # Add random delay to time table time\n",
    "    df['actual_time'] = df['time'].apply(\n",
    "                          lambda t: random_delay(y, mo, d, *t.split(':'))\n",
    "                        )\n",
    "\n",
    "    # Make actual time human readable\n",
    "    df['actual_time_str'] = df['actual_time'].apply(\n",
    "                              lambda t: time.strftime(\n",
    "                                '%Y/%m/%d %H:%M', time.localtime(t)\n",
    "                              )\n",
    "                            )\n",
    "\n",
    "    # Append this date's data to final data\n",
    "    final_data = final_data.append(df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add random crowd data\n",
    "final_data['crowd'] = random()\n",
    "\n",
    "# Store the final data in the csv\n",
    "final_data.to_csv('train_log.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
